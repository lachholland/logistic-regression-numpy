{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_fix(dataset, column, fill):\n",
    "    for i in range(dataset.shape[0]):\n",
    "        if not isinstance(dataset[i, column], str):\n",
    "            dataset[i, column] = fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data, column, encoding):\n",
    "   one_hot = np.zeros((len(data), len(encoding)))\n",
    "   for i in range(len(data)):\n",
    "      one_hot[i, encoding[data[i, column]]] = 1\n",
    "   encoded = np.concatenate((data, one_hot), axis=1)\n",
    "   return np.delete(encoded, column, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return  1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    z = np.dot(X, w) + b\n",
    "    y_pred = sigmoid(z)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y, y_hat):\n",
    "    eps = 1e-15\n",
    "    J = -np.mean(y * np.log(y_hat + eps) - (1 - y) * np.log(1 - y_hat + eps))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(X, y, y_hat):\n",
    "      m = X.shape[0]\n",
    "      dw = (1/m) * np.dot(X.T, (y_hat - y))\n",
    "      db = (1/m) * np.sum(y_hat - y)\n",
    "      return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, lr, epochs, bs=30):\n",
    "    m, n = X.shape\n",
    "    w = np.random.randn(n)\n",
    "    b = 0\n",
    "    loss_history = []\n",
    "    X = X.astype(np.float64)\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((m-1)//bs + 1):\n",
    "            b_start = i * bs\n",
    "            b_end = b_start + bs\n",
    "            xb = X[b_start:b_end]\n",
    "            yb = y[b_start:b_end]\n",
    "            y_hat = predict(xb, w, b)\n",
    "            dw, db = gradients(xb, yb, y_hat)\n",
    "            w -= lr*dw\n",
    "            b -= lr*db\n",
    "        loss = log_loss(y, sigmoid(np.dot(X, w) + b))\n",
    "        loss_history.append(loss)\n",
    "    return loss_history\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "y_train = train_data['Survived'].copy()\n",
    "train_data.drop(['PassengerId','Name', 'Survived','Age', 'Ticket', 'Fare', 'Cabin'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_numpy = train_data.values\n",
    "x_test_numpy = test_data.values\n",
    "null_fix(x_train_numpy, 4, 'S')\n",
    "null_fix(x_test_numpy, 10, 'S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_encoding = {'S': 0, 'C': 1, 'Q': 2}\n",
    "sex_encoding = {'male': 1, 'female': 0}\n",
    "x_train_encoded1 = one_hot_encoding(x_train_numpy, 4, embarked_encoding)\n",
    "x_train_encoded2 = one_hot_encoding(x_train_encoded1, 1, sex_encoding)\n",
    "y_train_numpy = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.7335469653913087,\n",
       " -1.8271867761382277,\n",
       " -1.0519017459351019,\n",
       " -0.4837373674552094,\n",
       " -0.1319095933277173,\n",
       " 0.06395271922578451,\n",
       " 0.16845538290113055,\n",
       " 0.22276313595962977,\n",
       " 0.24944110419753215,\n",
       " 0.2606915073553127,\n",
       " 0.2632681344085793,\n",
       " 0.26100113042250644,\n",
       " 0.2560983307876249,\n",
       " 0.24984218375593764,\n",
       " 0.24297763855401858,\n",
       " 0.23593436511307678,\n",
       " 0.22895642191759885,\n",
       " 0.22217866443212475,\n",
       " 0.21567193923217784,\n",
       " 0.2094698106362622,\n",
       " 0.20358432494852802,\n",
       " 0.19801527097059698,\n",
       " 0.19275559304647413,\n",
       " 0.18779453758188394,\n",
       " 0.1831194710058508,\n",
       " 0.1787169232268022,\n",
       " 0.17457318218127177,\n",
       " 0.17067462973456146,\n",
       " 0.16700792942315057,\n",
       " 0.1635601297731338,\n",
       " 0.16031871969193964,\n",
       " 0.15727165667344886,\n",
       " 0.15440737951347822,\n",
       " 0.15171481209077922,\n",
       " 0.14918336187624304,\n",
       " 0.14680291522454747,\n",
       " 0.14456383061757283,\n",
       " 0.14245693054471348,\n",
       " 0.14047349243821536,\n",
       " 0.13860523892933588,\n",
       " 0.13684432759796875,\n",
       " 0.13518334032564158,\n",
       " 0.13361527231578804,\n",
       " 0.13213352081015806,\n",
       " 0.13073187350430066,\n",
       " 0.12940449664793496,\n",
       " 0.12814592280762563,\n",
       " 0.12695103826908744,\n",
       " 0.12581507006362377,\n",
       " 0.12473357261614404,\n",
       " 0.12370241402900196,\n",
       " 0.12271776203451383,\n",
       " 0.12177606966756085,\n",
       " 0.12087406072644921,\n",
       " 0.12000871510393894,\n",
       " 0.11917725408021654,\n",
       " 0.11837712567518574,\n",
       " 0.11760599015876942,\n",
       " 0.11686170581528253,\n",
       " 0.11614231505190248,\n",
       " 0.11544603093249878,\n",
       " 0.11477122420737089,\n",
       " 0.11411641089748607,\n",
       " 0.11348024047931735,\n",
       " 0.11286148470392722,\n",
       " 0.11225902707201994,\n",
       " 0.11167185297562812,\n",
       " 0.11109904050719617,\n",
       " 0.11053975192818001,\n",
       " 0.10999322578200253,\n",
       " 0.1094587696302552,\n",
       " 0.10893575338636807,\n",
       " 0.10842360321749221,\n",
       " 0.10792179598292188,\n",
       " 0.1074298541759103,\n",
       " 0.1069473413350454,\n",
       " 0.10647385789134832,\n",
       " 0.10600903741777518,\n",
       " 0.10555254324876019,\n",
       " 0.1051040654387201,\n",
       " 0.10466331802994269,\n",
       " 0.10423003660196448,\n",
       " 0.1038039760762997,\n",
       " 0.10338490875219643,\n",
       " 0.10297262255090658,\n",
       " 0.10256691944773176,\n",
       " 0.1021676140728347,\n",
       " 0.10177453246344766,\n",
       " 0.10138751095168146,\n",
       " 0.10100639517359118,\n",
       " 0.10063103918653635,\n",
       " 0.10026130468313593,\n",
       " 0.09989706029128426,\n",
       " 0.09953818095077124,\n",
       " 0.09918454735802729,\n",
       " 0.09883604547140173,\n",
       " 0.09849256607019964,\n",
       " 0.09815400436142242,\n",
       " 0.09782025962882349,\n",
       " 0.09749123491948208]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = train(x_train_encoded2, y_train_numpy, 0.01, 100, 30)\n",
    "np.set_printoptions(linewidth=100, threshold=np.inf)\n",
    "display(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "223618a81968889eab31b4f4c56b9aad16fbce78f58c2e2cb1a3fe1b6384ba37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
